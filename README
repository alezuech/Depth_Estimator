###

Depth Estimator

This project is dedicated to the creation of a Deep Learning method able to process images and estimate the pixel-wise distance of the objects from the camera.
No State of the Art methods have been examined prior or during the elaboration of this project to avoid inadvertently copying them.

###

Objectives:
    1 - Create the pipeline for the creation of the training dataset.
        Notes - Blender 3D modeling tool is used. 

        1.1 - Some simple scenarios are created with basic object meshes (cubes, cylinders, spheres, ...), fixed lighting and (possibly) realistic textures (such as wood, rock, concrete, ...). 

        1.2 - To obtain multiple input images, the camera is randomly moved around the scenario when a new image is obtained.

        1.3 - To obtain the target depth image corresponding to a specific input image, create multiple lines starting from the camera and going towards the field of view. If a plane intersected these lines, the intersection points would form a 2D grid, whose size corresponds to the resolution of the rendered image. Each line can be projected into the center of a specific pixel of the rendered image. The depth associated to each pixel corresponds to the distance between the camera and the first intersection of the corresponding line to an object. If the line does not intersect anything, the depth is set to -1.


    2 - Create the deep learning model.